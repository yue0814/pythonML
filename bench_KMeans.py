# from time import time
# import numpy as np
# from sklearn.datasets import load_digits
# from sklearn.preprocessing import scale
# from sklearn import metrics


# np.random.seed()

# digits = load_digits()
# data = scale(digits.data)

# n_samples, n_features = data.shape
# n_digits = len(np.unique(digits.target))
# labels = digits.target

# sample_size = 300

# evaluate clustering

# metrics.homogeneity_score()
# metrics.silhouette_score()
# metrics.completeness_score()
# metrics.v_measure_score()
# metrics.adjusted_rand_score()
